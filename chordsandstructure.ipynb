{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e17388d",
   "metadata": {},
   "source": [
    "# Hierarchical HMM: Chords & Song Sections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e2a88c",
   "metadata": {},
   "source": [
    "## Data Cleaning & Augmentation\n",
    "Simplifying chords down to 42: base note (A-G) + accidental + major/minor(dim)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2ca3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c8/zh68_k6j30l283wd6sjg39280000gn/T/ipykernel_62647/1002697580.py:2: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"hf://datasets/ailsntua/Chordonomicon/chordonomicon_v2.csv\",usecols=[\"chords\", \"main_genre\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85185\n",
      "55641\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# Write song sections to csv\n",
    "df = pd.read_csv(\"hf://datasets/ailsntua/Chordonomicon/chordonomicon_v2.csv\",usecols=[\"chords\", \"main_genre\"])\n",
    "pop_structure = df[df[\"main_genre\"] == \"pop\"][[\"chords\"]].copy()\n",
    "pop_structure[\"chords\"] = pop_structure[\"chords\"].str.split(\" \")\n",
    "\n",
    "print(len(pop_structure)) # 85k\n",
    "\n",
    "# remove all songs with no section tags\n",
    "pop_structure = pop_structure[\n",
    "    pop_structure[\"chords\"].apply(\n",
    "        lambda tokens: any(token.startswith(\"<\") for token in tokens)\n",
    "    )\n",
    "]\n",
    "\n",
    "print(len(pop_structure)) # 55k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a85ea50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             sections\n",
      "0   [intro, verse, verse, verse, verse, verse, ver...\n",
      "4   [intro, verse, verse, verse, verse, chorus, ch...\n",
      "6   [intro, intro, intro, intro, intro, intro, ver...\n",
      "7   [intro, intro, intro, intro, intro, intro, int...\n",
      "8   [chorus, chorus, chorus, chorus, chorus, choru...\n",
      "10  [intro, intro, intro, intro, verse, verse, ver...\n",
      "24  [intro, intro, intro, intro, intro, verse, ver...\n",
      "25  [intro, intro, intro, intro, intro, verse, ver...\n",
      "26  [intro, intro, intro, intro, verse, verse, ver...\n",
      "27  [intro, intro, intro, intro, intro, intro, int...\n",
      "35  [chorus, chorus, chorus, chorus, chorus, choru...\n",
      "48  [intro, intro, intro, intro, intro, intro, int...\n",
      "50  [intro, intro, intro, verse, verse, verse, ver...\n",
      "54  [intro, intro, intro, intro, intro, intro, ver...\n",
      "60  [intro, verse, verse, verse, verse, verse, ver...\n"
     ]
    }
   ],
   "source": [
    "def expand_sections(tokens):\n",
    "    \"\"\"\n",
    "    Given token list [\"<intro_1>\", \"C\", \"<verse_1>\", \"F\", \"C\", \"G7\", ...]\n",
    "    Returns list of replicated section labels [\"intro\", \"intro\", \"verse\", \"verse\", \"verse\", \"verse\", ...]\n",
    "    \"\"\"\n",
    "    section_labels = []\n",
    "    current_section = None\n",
    "\n",
    "    for tok in tokens:\n",
    "        if tok.startswith(\"<\") and tok.endswith(\">\"):\n",
    "            raw = tok[1:-1] # drop <>\n",
    "            current_section = raw.split(\"_\")[0] # intro_1 --> intro\n",
    "        else:\n",
    "            section_labels.append(current_section) # replicate current section label if it's a chord\n",
    "    return section_labels\n",
    "\n",
    "\n",
    "pop_structure[\"sections\"] = pop_structure[\"chords\"].apply(expand_sections)\n",
    "pop_structure = pop_structure[[\"sections\"]]\n",
    "print(pop_structure.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "247f8472",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_structure.to_csv(\"chordonomicon_v2_sections.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1877f84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bridge', 'solo', 'verse', 'intro', 'outro', 'instrumental', 'interlude', 'chorus'}\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "unique_tags = set(\n",
    "    tag\n",
    "    for tags in pop_structure[\"sections\"]\n",
    "    for tag in tags\n",
    ")\n",
    "\n",
    "print(unique_tags)\n",
    "print(len(unique_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25a3bca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplifying chords down to set of 42\n",
    "notes = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]\n",
    "accs = [\"b\", \"s\", \"\"]\n",
    "all_notes_list = [note + acc for note in notes for acc in accs]\n",
    "\n",
    "def simplify_chord(chord: str) -> str:\n",
    "    \"\"\"\n",
    "    Removes chord quality from a chord.\n",
    "    \"\"\"\n",
    "    for note in all_notes_list:\n",
    "        if not chord.startswith(note):\n",
    "            continue\n",
    "\n",
    "        suffix = chord.removeprefix(note)\n",
    "        if suffix.startswith(\"min\") or suffix.startswith(\"dim\"):\n",
    "            return note + \"min\"\n",
    "        else:\n",
    "            return note\n",
    "\n",
    "    if chord == \"sC\":\n",
    "        return \"Cs\"\n",
    "\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75834f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c8/zh68_k6j30l283wd6sjg39280000gn/T/ipykernel_62647/3221364142.py:2: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"hf://datasets/ailsntua/Chordonomicon/chordonomicon_v2.csv\",usecols=[\"chords\", \"main_genre\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55641\n",
      "                                               chords\n",
      "0   [C, F, C, E, Amin, C, F, C, G, C, F, C, E, Ami...\n",
      "4   [C, G, C, G, C, F, Dmin, G, Dmin, G, C, G, C, ...\n",
      "6   [G, Bmin, Amin, D, G, Bmin, Amin, D, G, Emin, ...\n",
      "7   [Fsmin, Fs, B, E, Fs, B, E, Fsmin, B, As, Gsmi...\n",
      "8   [C, Amin, Dmin, G, C, G, Amin, Dmin, G, C, Dmi...\n",
      "10  [C, C, C, C, G, D, Emin, D, Emin, Amin, D, G, ...\n",
      "24  [Amin, Amin, F, Es, E, Amin, Amin, F, E, Amin,...\n",
      "25  [Emin, Emin, C, Bs, B, Emin, Emin, C, Bs, B, A...\n",
      "26  [A, D, A, D, A, D, A, D, A, D, A, G, A, D, A, ...\n",
      "27  [Amin, As, Amin, Amin, F, E, F, Amin, F, G, E,...\n",
      "35  [Eb, Bb, Gmin, F, Eb, Bb, Gmin, F, Eb, Bb, Gmi...\n",
      "48  [Amin, D, G, D, Emin, Amin, D, G, C, G, Amin, ...\n",
      "50  [C, C, G, C, Emin, Amin, Gmin, F, C, Dmin, G, ...\n",
      "54  [D, C, Bb, F, Dmin, C, Dmin, C, Bb, F, Dmin, C...\n",
      "60  [D, Fsmin, G, A, D, Fsmin, G, A, D, Fsmin, G, ...\n"
     ]
    }
   ],
   "source": [
    "# Write simplified chords to csv\n",
    "df = pd.read_csv(\"hf://datasets/ailsntua/Chordonomicon/chordonomicon_v2.csv\",usecols=[\"chords\", \"main_genre\"])\n",
    "pop_chords = df[df[\"main_genre\"] == \"pop\"][[\"chords\"]]\n",
    "pop_chords[\"chords\"] = pop_chords[\"chords\"].str.split(\" \")\n",
    "\n",
    "# remove all songs with no section tags, same as above\n",
    "pop_chords = pop_chords[\n",
    "    pop_chords[\"chords\"].apply(\n",
    "        lambda tokens: any(token.startswith(\"<\") for token in tokens)\n",
    "    )\n",
    "]\n",
    "\n",
    "print(len(pop_chords)) # 55k to match above\n",
    "\n",
    "pop_chords[\"chords\"] = pop_chords[\"chords\"].map(\n",
    "    lambda chords: [simplify_chord(chord) for chord in chords if not chord.startswith(\"<\")]\n",
    ")\n",
    "\n",
    "print(pop_chords.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5438541f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Eb', 'Dsmin', 'Db', 'Fmin', 'Amin', 'Gsmin', 'Fsmin', 'Gs', 'Bbmin', 'As', 'Cs', 'Bb', 'F', 'Ds', 'B', 'Dmin', 'Ebmin', 'A', 'G', 'Fs', 'D', 'Gmin', 'Gb', 'Es', 'Emin', 'Asmin', 'Bmin', 'Abmin', 'E', 'Cmin', 'Dbmin', 'C', 'Ab', 'Csmin', 'Gbmin', 'Bs'}\n",
      "36\n",
      "Not observed in dataset: {'Cb', 'Esmin', 'Cbmin', 'Bsmin', 'Fbmin', 'Fb'}\n"
     ]
    }
   ],
   "source": [
    "unique_chords = set(\n",
    "    chord\n",
    "    for chords in pop_chords[\"chords\"]\n",
    "    for chord in chords\n",
    ")\n",
    "\n",
    "print(unique_chords)\n",
    "print(len(unique_chords))\n",
    "\n",
    "notes = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]\n",
    "accs = [\"b\", \"s\", \"\"]\n",
    "third = [\"\", \"min\"]\n",
    "all_chords = [note + acc + t for note in notes for acc in accs for t in third]\n",
    "\n",
    "missing = set(all_chords) - unique_chords\n",
    "if missing:\n",
    "    print(f\"Not observed in dataset: \" + str(missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4fdfb99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_chords.to_csv(\"chordonomicon_v2_simplified.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22cc383",
   "metadata": {},
   "source": [
    "## Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebabf2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c8/zh68_k6j30l283wd6sjg39280000gn/T/ipykernel_69655/2273511548.py:44: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering: 55641\n",
      "                                               chords main_genre  \\\n",
      "0   <intro_1> C <verse_1> F C E7 Amin C F C G7 C F...        pop   \n",
      "4   <intro_1> C <verse_1> G C G C <chorus_1> F Dmi...        pop   \n",
      "6   <intro_1> G Bmin Amin D G Bmin <verse_1> Amin ...        pop   \n",
      "7   <intro_1> Fsmin Fsno3d Bno3d E/B Fsno3d Bno3d ...        pop   \n",
      "8   <chorus_1> C Amin Dmin G C G Amin Dmin G C <ve...        pop   \n",
      "10  <intro_1> Cmaj7 C Cmaj7 C <verse_1> G D Emin D...        pop   \n",
      "24  <intro_1> Amin Amin7/G Fmaj7 Esus4 E <verse_1>...        pop   \n",
      "25  <intro_1> Emin Emin7 Cmaj7 Bsus4 B <verse_1> E...        pop   \n",
      "26  <intro_1> A D A D <verse_1> A D A D A D A G <c...        pop   \n",
      "27  <intro_1> Amin Asus2 Amin Amin7/G F E7 F <vers...        pop   \n",
      "\n",
      "                                               tokens  \\\n",
      "0   [<intro_1>, C, <verse_1>, F, C, E7, Amin, C, F...   \n",
      "4   [<intro_1>, C, <verse_1>, G, C, G, C, <chorus_...   \n",
      "6   [<intro_1>, G, Bmin, Amin, D, G, Bmin, <verse_...   \n",
      "7   [<intro_1>, Fsmin, Fsno3d, Bno3d, E/B, Fsno3d,...   \n",
      "8   [<chorus_1>, C, Amin, Dmin, G, C, G, Amin, Dmi...   \n",
      "10  [<intro_1>, Cmaj7, C, Cmaj7, C, <verse_1>, G, ...   \n",
      "24  [<intro_1>, Amin, Amin7/G, Fmaj7, Esus4, E, <v...   \n",
      "25  [<intro_1>, Emin, Emin7, Cmaj7, Bsus4, B, <ver...   \n",
      "26  [<intro_1>, A, D, A, D, <verse_1>, A, D, A, D,...   \n",
      "27  [<intro_1>, Amin, Asus2, Amin, Amin7/G, F, E7,...   \n",
      "\n",
      "                                        simple_chords  \\\n",
      "0   [C, F, C, E, Amin, C, F, C, G, C, F, C, E, Ami...   \n",
      "4   [C, G, C, G, C, F, Dmin, G, Dmin, G, C, G, C, ...   \n",
      "6   [G, Bmin, Amin, D, G, Bmin, Amin, D, G, Emin, ...   \n",
      "7   [Fsmin, Fs, B, E, Fs, B, E, Fsmin, B, As, Gsmi...   \n",
      "8   [C, Amin, Dmin, G, C, G, Amin, Dmin, G, C, Dmi...   \n",
      "10  [C, C, C, C, G, D, Emin, D, Emin, Amin, D, G, ...   \n",
      "24  [Amin, Amin, F, Es, E, Amin, Amin, F, E, Amin,...   \n",
      "25  [Emin, Emin, C, Bs, B, Emin, Emin, C, Bs, B, A...   \n",
      "26  [A, D, A, D, A, D, A, D, A, D, A, G, A, D, A, ...   \n",
      "27  [Amin, As, Amin, Amin, F, E, F, Amin, F, G, E,...   \n",
      "\n",
      "                                             sections  \n",
      "0   [intro, verse, verse, verse, verse, verse, ver...  \n",
      "4   [intro, verse, verse, verse, verse, chorus, ch...  \n",
      "6   [intro, intro, intro, intro, intro, intro, ver...  \n",
      "7   [intro, intro, intro, intro, intro, intro, int...  \n",
      "8   [chorus, chorus, chorus, chorus, chorus, choru...  \n",
      "10  [intro, intro, intro, intro, verse, verse, ver...  \n",
      "24  [intro, intro, intro, intro, intro, verse, ver...  \n",
      "25  [intro, intro, intro, intro, intro, verse, ver...  \n",
      "26  [intro, intro, intro, intro, verse, verse, ver...  \n",
      "27  [intro, intro, intro, intro, intro, intro, int...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "notes = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]\n",
    "accs = [\"b\", \"s\", \"\"]\n",
    "all_notes_list = [note + acc for note in notes for acc in accs]\n",
    "\n",
    "def simplify_chord(chord: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert chord like Csmin, Abdim, G, Fsmin → Csmin, Abmin, G, Fsmin.\n",
    "    Remove quality except treat min/dim as minor.\n",
    "    \"\"\"\n",
    "    for note in all_notes_list:\n",
    "        if chord.startswith(note):\n",
    "            suffix = chord[len(note):]\n",
    "            if suffix.startswith((\"min\", \"dim\")):\n",
    "                return note + \"min\"\n",
    "            else:\n",
    "                return note\n",
    "\n",
    "    if chord == \"sC\":\n",
    "        return \"Cs\"\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def expand_sections(tokens):\n",
    "    \"\"\"\n",
    "    Produce a section label for each actual chord token.\n",
    "    \"\"\"\n",
    "    section_labels = []\n",
    "    current_section = None\n",
    "\n",
    "    for tok in tokens:\n",
    "        if tok.startswith(\"<\") and tok.endswith(\">\"):\n",
    "            raw = tok[1:-1]\n",
    "            current_section = raw.split(\"_\")[0]\n",
    "        else:\n",
    "            section_labels.append(current_section)\n",
    "    return section_labels\n",
    "\n",
    "\n",
    "####### Main Processing #######\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"hf://datasets/ailsntua/Chordonomicon/chordonomicon_v2.csv\",\n",
    "    usecols=[\"chords\", \"main_genre\"]\n",
    ")\n",
    "\n",
    "# Filter only pop songs\n",
    "pop_df = df[df[\"main_genre\"] == \"pop\"].copy()\n",
    "pop_df[\"tokens\"] = pop_df[\"chords\"].str.split(\" \")\n",
    "\n",
    "# Remove songs with no section tags\n",
    "pop_df = pop_df[\n",
    "    pop_df[\"tokens\"].apply(lambda toks: any(tok.startswith(\"<\") for tok in toks))\n",
    "].copy()\n",
    "\n",
    "print(\"After filtering:\", len(pop_df))  # 55k\n",
    "\n",
    "# Extract chords (simplified) and sections in aligned lists\n",
    "pop_df[\"simple_chords\"] = pop_df[\"tokens\"].apply(\n",
    "    lambda toks: [simplify_chord(tok) for tok in toks if not tok.startswith(\"<\")]\n",
    ")\n",
    "\n",
    "pop_df[\"sections\"] = pop_df[\"tokens\"].apply(expand_sections)\n",
    "\n",
    "# Sanity check: same length\n",
    "assert all(\n",
    "    len(c) == len(s)\n",
    "    for c, s in zip(pop_df[\"simple_chords\"], pop_df[\"sections\"])\n",
    "), \"Mismatch in chord-section lengths!\"\n",
    "\n",
    "print(pop_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c921601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed sections: {'intro', 'verse', 'interlude', 'chorus', 'solo', 'outro', 'bridge', 'instrumental'}\n",
      "8\n",
      "\n",
      "Section: intro\n",
      "                                  chords\n",
      "0                                    [C]\n",
      "1                                    [C]\n",
      "2            [G, Bmin, Amin, D, G, Bmin]\n",
      "3  [Fsmin, Fs, B, E, Fs, B, E, Fsmin, B]\n",
      "4                           [C, C, C, C]\n",
      "Num rows: 36886\n",
      "\n",
      "Section: verse\n",
      "                                              chords\n",
      "0  [F, C, E, Amin, C, F, C, G, C, F, C, E, Amin, ...\n",
      "1                           [G, C, G, C, G, C, G, C]\n",
      "2  [Amin, D, G, Emin, Amin, D, G, Emin, Amin, D, ...\n",
      "3  [Dmin, C, Dmin, C, Amin, Dmin, G, Dmin, C, Dmi...\n",
      "4   [G, D, Emin, D, Emin, Amin, D, G, G, C, C, Amin]\n",
      "Num rows: 52380\n",
      "\n",
      "Section: interlude\n",
      "                                              chords\n",
      "0                  [F, G, Emin, Amin, Dmin, G, C, G]\n",
      "1  [C, F, G, Cmin, G, Cmin, D, G, Ab, Cmin, G, Cmin]\n",
      "2  [E, E, B, E, E, E, A, B, E, E, B, E, E, A, B, ...\n",
      "3  [Amin, G, C, Amin, G, C, G, Amin, G, C, Dmin, ...\n",
      "4  [G, D, A, G, D, A, Bmin, G, D, A, Bmin, G, D, ...\n",
      "Num rows: 6994\n",
      "\n",
      "Section: chorus\n",
      "                                              chords\n",
      "0  [F, C, F, C, G, C, F, C, E, Amin, C, F, G, C, ...\n",
      "1  [F, Dmin, G, Dmin, G, C, F, Dmin, G, Dmin, G, ...\n",
      "2  [G, Emin, Amin, D, G, Emin, Amin, D, G, Emin, ...\n",
      "3  [As, Gsmin, B, Csmin, Gsmin, Csmin, Gsmin, Fs,...\n",
      "4  [C, Amin, Dmin, G, C, G, Amin, Dmin, G, C, C, ...\n",
      "Num rows: 49098\n",
      "\n",
      "Section: solo\n",
      "                                              chords\n",
      "0                                                [D]\n",
      "1                                       [C, G, D, G]\n",
      "2                                 [Amin, C, D, Amin]\n",
      "3                  [D, Bmin, G, A, D, Bmin, G, A, D]\n",
      "4  [Amin, F, Amin, F, Amin, F, Amin, G, F, Amin, ...\n",
      "Num rows: 2466\n",
      "\n",
      "Section: outro\n",
      "                                              chords\n",
      "0  [Amin, D, G, Emin, Amin, D, G, Emin, Amin, D, ...\n",
      "1                         [B, E, Fsmin, B, E, Fsmin]\n",
      "2               [Dmin, G, C, Amin, Dmin, G, C, G, C]\n",
      "3                                       [C, C, Amin]\n",
      "4         [F, G, E, Amin, F, G, E, Amin, F, G, Amin]\n",
      "Num rows: 24195\n",
      "\n",
      "Section: bridge\n",
      "                                              chords\n",
      "0                                    [G, C, Amin, C]\n",
      "1                                       [A, D, A, D]\n",
      "2                              [F, G, E, Amin, F, E]\n",
      "3                                          [Amin, D]\n",
      "4  [Dmin, Emin, F, G, Emin, Amin, Dmin, G, C, Dmi...\n",
      "Num rows: 24215\n",
      "\n",
      "Section: instrumental\n",
      "                                         chords\n",
      "0  [Emin, Emin, C, Bs, B, Amin, G, Amin, Bs, B]\n",
      "1          [F, G, Emin, Amin, F, G, Emin, Amin]\n",
      "2            [E, A, E, A, Asmin, B, C, B, E, B]\n",
      "3        [Gs, Csmin, B, Amin, E, B, A, Amin, E]\n",
      "4      [Ab, Db, Eb, Ab, Db, Eb, Db, Eb, Db, Eb]\n",
      "Num rows: 7163\n"
     ]
    }
   ],
   "source": [
    "# Extract chords by section type -> 8 dataframes\n",
    "import pandas as pd\n",
    "\n",
    "# get all section labels\n",
    "all_sections = set(\n",
    "    tag\n",
    "    for tags in pop_df[\"sections\"]\n",
    "    for tag in tags\n",
    ")\n",
    "print(\"Observed sections:\", str(all_sections))\n",
    "print(len(all_sections))\n",
    "\n",
    "# section -> df with column \"chords\"\n",
    "section_dfs = {}\n",
    "for section in all_sections:\n",
    "    song_chords_per_sect = []\n",
    "\n",
    "    for chords, secs in zip(pop_df[\"simple_chords\"], pop_df[\"sections\"]):\n",
    "        # indices where the section appears\n",
    "        idxs = [i for i, s in enumerate(secs) if s == section]\n",
    "\n",
    "        # don't record in df if the song doesn't have the section\n",
    "        if not idxs:\n",
    "            continue\n",
    "\n",
    "        # extract the chords at these indices\n",
    "        seq = [chords[i] for i in idxs]\n",
    "\n",
    "        song_chords_per_sect.append(seq)\n",
    "\n",
    "    section_dfs[section] = pd.DataFrame({\"chords\": song_chords_per_sect})\n",
    "\n",
    "\n",
    "for section in all_sections:\n",
    "    print(f\"\\nSection: {section}\")\n",
    "    print(section_dfs[section].head())\n",
    "    print(\"Num rows:\", len(section_dfs[section]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc79ae1f",
   "metadata": {},
   "source": [
    "# Learning\n",
    "Compute n-gram counts using CountVectorizer library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1f11b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def count_n_grams(data, n: int = 1) -> pd.DataFrame:\n",
    "    word_vectorizer = CountVectorizer(\n",
    "        ngram_range=(1, n),\n",
    "        analyzer=\"word\",\n",
    "        token_pattern=r\"(?u)\\b\\w+\\b\",\n",
    "        lowercase=False,\n",
    "    )\n",
    "\n",
    "    sparse_matrix = word_vectorizer.fit_transform(\n",
    "        data.map(lambda chords: \" \".join(chords))\n",
    "    )\n",
    "\n",
    "    frequencies = sum(sparse_matrix).toarray()[0]\n",
    "\n",
    "    df_all = pd.DataFrame(\n",
    "        frequencies,\n",
    "        index=word_vectorizer.get_feature_names_out(),\n",
    "        columns=[\"count\"],\n",
    "    )\n",
    "\n",
    "    return df_all.groupby(by=lambda chords: len(chords.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "612d407c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# Calculate transition matrix probabilities\n",
    "# alpha is additive smoothing\n",
    "def compute_unigram_prob(n_gram_counts, vocab, alpha=1.0):\n",
    "    unigram = n_gram_counts.get_group(1).copy()\n",
    "    unigram = unigram.reindex(vocab, fill_value=0)\n",
    "    vocab_size = len(vocab)\n",
    "    total_count = unigram[\"count\"].sum()\n",
    "\n",
    "    probs = (unigram[\"count\"] + alpha) / (total_count + alpha * vocab_size)\n",
    "    df = pd.DataFrame([probs.values], \n",
    "                      index=[\"\"],\n",
    "                      columns=vocab)\n",
    "    return df\n",
    "\n",
    "# def compute_bigram_prob(n_gram_counts, alpha=1.0):\n",
    "#     bigram = n_gram_counts.get_group(2)\n",
    "#     bigram[\"evidence\"] = bigram.index.map(lambda s: s.split()[0]) # get (n-1)-length evidence\n",
    "#     bigram[\"next\"] = bigram.index.map(lambda s: s.split()[1]) # next chords\n",
    "\n",
    "#     full_index = pd.MultiIndex.from_product([all_chords_list, all_chords_list], names=[\"evidence\", \"next\"])\n",
    "#     bigram = bigram.set_index([\"evidence\", \"next\"])\n",
    "#     bigram = bigram.reindex(full_index, fill_value=0)\n",
    "\n",
    "#     evidence_counts = bigram[\"count\"].groupby(level=\"evidence\").transform(\"sum\")\n",
    "#     num_next = bigram.index.get_level_values(\"next\").nunique()\n",
    "#     bigram[\"prob\"] = (bigram[\"count\"] + alpha) / (evidence_counts + alpha * num_next)\n",
    "\n",
    "#     # 2d dataframe\n",
    "#     return bigram[\"prob\"].unstack(fill_value=0.0)\n",
    "\n",
    "def compute_ngram_prob(n_gram_counts, vocab, n : int = 2, alpha=1.0):\n",
    "    ngram = n_gram_counts.get_group(n).copy()\n",
    "\n",
    "    ngram[\"evidence\"] = ngram.index.map(lambda s: \" \".join(s.split()[:-1]))\n",
    "    ngram[\"next\"] = ngram.index.map(lambda s: s.split()[-1])\n",
    "    \n",
    "    # generate all possible (n-1)-length chord sequeneces\n",
    "    all_evidence_seq = [\" \".join(evidence) for evidence in itertools.product(vocab, repeat=(n - 1))]\n",
    "    full_index = pd.MultiIndex.from_product([all_evidence_seq, vocab], names=[\"evidence\", \"next\"])\n",
    "\n",
    "    # reindex to (vocab_size^(n-1), n)\n",
    "    ngram = ngram.set_index([\"evidence\", \"next\"])\n",
    "    ngram = ngram.reindex(full_index, fill_value=0)\n",
    "\n",
    "    # compute probs\n",
    "    evidence_counts = ngram[\"count\"].groupby(level=\"evidence\").transform(\"sum\")\n",
    "    vocab_size = len(vocab)\n",
    "    ngram[\"prob\"] = (ngram[\"count\"] + alpha) / (evidence_counts + alpha * vocab_size)\n",
    "\n",
    "    # 2d df transition matrix\n",
    "    return ngram[\"prob\"].unstack(fill_value=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2c8621",
   "metadata": {},
   "source": [
    "Compute n-gram counts for section labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "573b0cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                count\n",
      "solo            28782\n",
      "instrumental    78982\n",
      "interlude       79954\n",
      "outro          237375\n",
      "bridge         300348\n",
      "intro          306352\n",
      "verse         1775400\n",
      "chorus        1881980 \n",
      "\n",
      "\n",
      "                     count\n",
      "solo intro               3\n",
      "solo instrumental        6\n",
      "outro interlude         10\n",
      "outro bridge            13\n",
      "instrumental solo       16\n",
      "...                    ...\n",
      "outro outro         212670\n",
      "intro intro         268478\n",
      "bridge bridge       272191\n",
      "verse verse        1665286\n",
      "chorus chorus      1759010\n",
      "\n",
      "[64 rows x 1 columns] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sections\n",
    "\n",
    "n = 2 # S_t+1 only depends on S_t\n",
    "\n",
    "pop_sections = pop_df['sections']\n",
    "n_gram_cnts = count_n_grams(pop_sections, n)\n",
    "for key, _ in n_gram_cnts:\n",
    "    print(n_gram_cnts.get_group(key).sort_values(by='count'), \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b1cc0109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intro</th>\n",
       "      <th>verse</th>\n",
       "      <th>interlude</th>\n",
       "      <th>chorus</th>\n",
       "      <th>solo</th>\n",
       "      <th>outro</th>\n",
       "      <th>bridge</th>\n",
       "      <th>instrumental</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>0.065332</td>\n",
       "      <td>0.378616</td>\n",
       "      <td>0.017051</td>\n",
       "      <td>0.401345</td>\n",
       "      <td>0.006138</td>\n",
       "      <td>0.050622</td>\n",
       "      <td>0.064051</td>\n",
       "      <td>0.016844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     intro     verse  interlude    chorus      solo     outro    bridge  \\\n",
       "  0.065332  0.378616   0.017051  0.401345  0.006138  0.050622  0.064051   \n",
       "\n",
       "  instrumental  \n",
       "      0.016844  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sections = list(all_sections)\n",
    "\n",
    "# Section unigram probs\n",
    "unigram_probs_sec = compute_unigram_prob(n_gram_cnts, all_sections)\n",
    "print(unigram_probs_sec.shape)\n",
    "unigram_probs_sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e0375f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>next</th>\n",
       "      <th>bridge</th>\n",
       "      <th>chorus</th>\n",
       "      <th>instrumental</th>\n",
       "      <th>interlude</th>\n",
       "      <th>intro</th>\n",
       "      <th>outro</th>\n",
       "      <th>solo</th>\n",
       "      <th>verse</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evidence</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bridge</th>\n",
       "      <td>0.910917</td>\n",
       "      <td>0.061929</td>\n",
       "      <td>0.002734</td>\n",
       "      <td>0.002172</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.008296</td>\n",
       "      <td>0.001064</td>\n",
       "      <td>0.012714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chorus</th>\n",
       "      <td>0.010745</td>\n",
       "      <td>0.946252</td>\n",
       "      <td>0.003727</td>\n",
       "      <td>0.003581</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.009316</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.025122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instrumental</th>\n",
       "      <td>0.016229</td>\n",
       "      <td>0.030211</td>\n",
       "      <td>0.880371</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.011977</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.059706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interlude</th>\n",
       "      <td>0.011745</td>\n",
       "      <td>0.029250</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.882058</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.008388</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>0.066145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intro</th>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.011479</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.878746</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.107248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outro</th>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.001748</td>\n",
       "      <td>0.996378</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>solo</th>\n",
       "      <td>0.011450</td>\n",
       "      <td>0.034279</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.001124</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.008324</td>\n",
       "      <td>0.912756</td>\n",
       "      <td>0.031680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verse</th>\n",
       "      <td>0.003046</td>\n",
       "      <td>0.052321</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.940532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "next            bridge    chorus  instrumental  interlude     intro     outro  \\\n",
       "evidence                                                                        \n",
       "bridge        0.910917  0.061929      0.002734   0.002172  0.000174  0.008296   \n",
       "chorus        0.010745  0.946252      0.003727   0.003581  0.000295  0.009316   \n",
       "instrumental  0.016229  0.030211      0.880371   0.000894  0.000396  0.011977   \n",
       "interlude     0.011745  0.029250      0.001019   0.882058  0.000264  0.008388   \n",
       "intro         0.000475  0.011479      0.000661   0.000609  0.878746  0.000560   \n",
       "outro         0.000066  0.000295      0.000548   0.000052  0.001748  0.996378   \n",
       "solo          0.011450  0.034279      0.000246   0.001124  0.000140  0.008324   \n",
       "verse         0.003046  0.052321      0.000990   0.001215  0.000050  0.001597   \n",
       "\n",
       "next              solo     verse  \n",
       "evidence                          \n",
       "bridge        0.001064  0.012714  \n",
       "chorus        0.000962  0.025122  \n",
       "instrumental  0.000217  0.059706  \n",
       "interlude     0.001132  0.066145  \n",
       "intro         0.000223  0.107248  \n",
       "outro         0.000126  0.000787  \n",
       "solo          0.912756  0.031680  \n",
       "verse         0.000249  0.940532  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Section bigram probs\n",
    "bigram_probs_sec = compute_ngram_prob(n_gram_cnts, all_sections, n=2)\n",
    "print(bigram_probs_sec.shape)\n",
    "bigram_probs_sec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7436dec4",
   "metadata": {},
   "source": [
    "Compute n-gram counts for chords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "219bf487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary of all possible chords (flats consolidated with sharps)\n",
    "notes = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]\n",
    "accs = [\"b\", \"s\", \"\"]\n",
    "third = [\"\", \"min\"]\n",
    "all_chords = [note + acc + t for note in notes for acc in accs for t in third]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b8ec1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing section: intro with 36886 sequences\n",
      "Processing section: verse with 52380 sequences\n",
      "Processing section: interlude with 6994 sequences\n",
      "Processing section: chorus with 49098 sequences\n",
      "Processing section: solo with 2466 sequences\n",
      "Processing section: outro with 24195 sequences\n",
      "Processing section: bridge with 24215 sequences\n",
      "Processing section: instrumental with 7163 sequences\n",
      "Sections processed: ['intro', 'verse', 'interlude', 'chorus', 'solo', 'outro', 'bridge', 'instrumental']\n",
      "Chorus unigram probability shape: (1, 42)\n"
     ]
    }
   ],
   "source": [
    "n = 3\n",
    "section_n_gram_counts = {} # index: section_n_gram_counts[\"intro\"][1]\n",
    "section_n_gram_probs = {}\n",
    "\n",
    "for sec, df_sec in section_dfs.items():\n",
    "    print(f\"Processing section: {sec} with {len(df_sec)} sequences\")\n",
    "\n",
    "    # Extract the Series of chord lists\n",
    "    chord_series = df_sec[\"chords\"]\n",
    "\n",
    "    # Compute counts for all n-grams up to n\n",
    "    counts_df = count_n_grams(chord_series, n)\n",
    "\n",
    "    # Store counts by n (1 → unigrams, 2 → bigrams, ...)\n",
    "    section_n_gram_counts[sec] = counts_df\n",
    "\n",
    "    # Compute probabilities for each n\n",
    "    section_n_gram_probs[sec] = {}\n",
    "\n",
    "    # Unigrams\n",
    "    unigram_probs = compute_unigram_prob(counts_df, all_chords)\n",
    "    section_n_gram_probs[sec][1] = unigram_probs\n",
    "\n",
    "    # Bigrams\n",
    "    if n >= 2:\n",
    "        # You would define this similarly to your unigram version\n",
    "        bigram_probs = compute_ngram_prob(counts_df, all_chords, n=2)\n",
    "        section_n_gram_probs[sec][2] = bigram_probs\n",
    "\n",
    "    # Trigrams\n",
    "    if n >= 3:\n",
    "        trigram_probs = compute_ngram_prob(counts_df, all_chords, n=3)\n",
    "        section_n_gram_probs[sec][3] = trigram_probs\n",
    "\n",
    "############################################################\n",
    "# Example usage\n",
    "############################################################\n",
    "\n",
    "print(\"Sections processed:\", list(section_n_gram_counts.keys()))\n",
    "\n",
    "# Access unigram probabilities for the chorus\n",
    "chorus_unigrams = section_n_gram_probs[\"chorus\"][1]\n",
    "print(\"Chorus unigram probability shape:\", chorus_unigrams.shape)\n",
    "\n",
    "# Access trigram counts for bridge\n",
    "bridge_trigrams = section_n_gram_counts[\"bridge\"].get_group(3)   # optional\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa46131",
   "metadata": {},
   "source": [
    "# Inference\n",
    "Deterministic and probabilistic methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ab1ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def deterministic_inference(evidence):\n",
    "    # evidence: string of n-1 space-separated chords\n",
    "    \n",
    "    n = len(evidence.split()) + 1\n",
    "    ngram_probs = unigram_probs if n == 1 else (bigram_probs if n == 2 else trigram_probs)\n",
    "\n",
    "    if evidence not in ngram_probs.index:\n",
    "        raise KeyError(f\"Evidence '{evidence}' not found in {n}-gram table\")\n",
    "    \n",
    "    row_probs = ngram_probs.loc[evidence]\n",
    "    return row_probs.idxmax() # returns next chord w highest prob, if there are several, the first one in col order\n",
    "\n",
    "def probabilistic_inference(evidence):\n",
    "    # evidence: string of n-1 space-separated chords\n",
    "    \n",
    "    n = len(evidence.split()) + 1\n",
    "    ngram_probs = unigram_probs if n == 1 else (bigram_probs if n == 2 else trigram_probs)\n",
    "\n",
    "    if evidence not in ngram_probs.index:\n",
    "        raise KeyError(f\"Evidence '{evidence}' not found in {n}-gram table\")\n",
    "    \n",
    "    row_probs = ngram_probs.loc[evidence]\n",
    "    cdf = np.cumsum(row_probs.values) # create cumulative distribution over next possible chord\n",
    "\n",
    "    # sample over dist\n",
    "    seed = np.random.random()\n",
    "    idx = np.searchsorted(cdf, seed)\n",
    "    \n",
    "    return row_probs.index[idx] # return probabilistically chosen next chord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3734191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Csmin', 'Gs', 'A', 'E', 'Bmin', 'D', 'A', 'Fsmin', 'Csmin', 'E', 'A', 'D', 'Fsmin', 'D', 'A', 'Fsmin']\n"
     ]
    }
   ],
   "source": [
    "### test inference for bigram ###\n",
    "seq = []\n",
    "\n",
    "for _ in range(16):\n",
    "    if len(seq) == 0:\n",
    "        evidence = \"\"\n",
    "    elif len(seq) == 1:\n",
    "        evidence = seq[-1]\n",
    "    else:\n",
    "        evidence = \" \".join(seq[-2:])\n",
    "\n",
    "    next_chord = probabilistic_inference(evidence) # can change to deterministic_inference()\n",
    "    seq.append(next_chord)\n",
    "\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea16a395",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Evaluate log-likelihood of an n-gram given a song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "aaae9ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def song_log_likelihood_ngram(song, n, ngram_probs):\n",
    "    # song: list of chords in song\n",
    "    # n: order of the n-gram model\n",
    "    # ngram_probs: dict[context_tuple] -> dict[target] = P(target | context)\n",
    "    # ex: trigram ngram_prob = dict[(chord1, chord2)] = {chord0:P,...,chordV:P}, dict[chord3] = P(chord3 | chord1, chord2)\n",
    "    # vocab_size: 42 or 36?\n",
    "\n",
    "    ll = 0.0\n",
    "    if len(song) < n:\n",
    "        return 0.0\n",
    "\n",
    "    for t in range(n-1, len(song)):\n",
    "        if n == 1:\n",
    "            context = \"\"\n",
    "        else:\n",
    "            context = \" \".join(song[t-(n-1):t])\n",
    "\n",
    "        target = song[t]\n",
    "\n",
    "        try:\n",
    "            p = ngram_probs.loc[context, target]\n",
    "        except KeyError:\n",
    "            print(f\"KeyError given evidence {context}\")\n",
    "            p = 1e-12\n",
    "\n",
    "        if p <= 0:\n",
    "            p = 1e-12\n",
    "        \n",
    "        ll += np.log(p)\n",
    "\n",
    "    return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c27a6598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-35.438954926606584\n"
     ]
    }
   ],
   "source": [
    "# test log-likelihood\n",
    "print(song_log_likelihood_ngram(seq, 2, bigram_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa54e55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_accuracy_ngram(song, n, ngram_probs, k=5):\n",
    "    # song: list of chords in song\n",
    "    # n: order of the n-gram model\n",
    "    # ngram_probs: DataFrame with index=evidence, columns=next chords\n",
    "    # k: number of top predictions to consider\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    if len(song) < n:\n",
    "        return 0.0\n",
    "    \n",
    "    for t in range(n-1, len(song)):\n",
    "        if n == 1:\n",
    "            context = \"\"\n",
    "        else:\n",
    "            context = \" \".join(song[t-(n-1):t])\n",
    "        \n",
    "        target = song[t]\n",
    "        \n",
    "        try:\n",
    "            prob_row = ngram_probs.loc[context]\n",
    "            \n",
    "            top_k_chords = prob_row.nlargest(k).index.tolist()\n",
    "            \n",
    "            if target in top_k_chords:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "            \n",
    "        except KeyError:\n",
    "            total += 1\n",
    "    \n",
    "    return correct / total if total > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683b1f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on top-k accuracy\n",
    "print(f\"Top-1: {top_k_accuracy_ngram(seq, 2, bigram_probs, k=1):.4f}\")\n",
    "print(f\"Top-3: {top_k_accuracy_ngram(seq, 2, bigram_probs, k=3):.4f}\")\n",
    "print(f\"Top-5: {top_k_accuracy_ngram(seq, 2, bigram_probs, k=5):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
