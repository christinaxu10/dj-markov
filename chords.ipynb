{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5e2a88c",
   "metadata": {},
   "source": [
    "# Data Cleaning & Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123113ab",
   "metadata": {},
   "source": [
    "## Simplify chords\n",
    "\n",
    "Simplifying chords down to 42: base note (A-G) + accidental + major/minor(dim)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cfdd3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25a3bca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simplifying chords down to set of 42 ###\n",
    "notes = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]\n",
    "accs = [\"b\", \"s\", \"\"]\n",
    "all_notes_list = [note + acc for note in notes for acc in accs]\n",
    "\n",
    "def simplify_chord(chord: str) -> str:\n",
    "    \"\"\"\n",
    "    Removes chord quality from a chord.\n",
    "    \"\"\"\n",
    "    for note in all_notes_list:\n",
    "        if not chord.startswith(note):\n",
    "            continue\n",
    "\n",
    "        suffix = chord.removeprefix(note)\n",
    "        if suffix.startswith(\"min\") or suffix.startswith(\"dim\"):\n",
    "            return note + \"min\"\n",
    "        else:\n",
    "            return note\n",
    "\n",
    "    if chord == \"sC\":\n",
    "        return \"Cs\"\n",
    "\n",
    "    # print(chord)\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59256c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7k/s33bvpvd04q3y60x6szp7f2m0000gn/T/ipykernel_1043/3360250008.py:1: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"chordonomicon_v2.csv\", usecols=[\"id\", \"chords\", \"main_genre\"])\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"chordonomicon_v2.csv\", usecols=[\"id\", \"chords\", \"main_genre\"])\n",
    "df[\"chords\"] = (\n",
    "    df[\"chords\"]\n",
    "    .str.split(\" \")\n",
    "    .map(lambda lst: [simplify_chord(x) for x in lst if not x.startswith(\"<\")])\n",
    ")\n",
    "df.to_csv(\"chordonomicon_v2_simplified.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8752cd",
   "metadata": {},
   "source": [
    "Optionally, also collaps both sharp and flat accents to sharp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9f68660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_and_standardize(chord: str) -> str:\n",
    "    \"\"\"\n",
    "    Simplifies chord quality (min/dim) and standardizes flat prefixes.\n",
    "    \"\"\"\n",
    "    # --- 1) Simplification (your original simplify_chord) ---\n",
    "    simplified = \"\"\n",
    "    for note in all_notes_list:\n",
    "        if chord.startswith(note):\n",
    "            suffix = chord[len(note):]\n",
    "            if suffix.startswith(\"min\") or suffix.startswith(\"dim\"):\n",
    "                simplified = note + \"min\"\n",
    "            else:\n",
    "                simplified = note\n",
    "            break\n",
    "\n",
    "    if chord == \"sC\":\n",
    "        simplified = \"Cs\"\n",
    "\n",
    "    if simplified == \"\":\n",
    "        simplified = chord  # fallback to original if nothing matched\n",
    "\n",
    "    # --- 2) Standardization (your standardize_chord_prefix) ---\n",
    "    flat_to_sharp = {\n",
    "        \"Bb\": \"As\",\n",
    "        \"Db\": \"Cs\",\n",
    "        \"Eb\": \"Ds\",\n",
    "        \"Gb\": \"Fs\",\n",
    "        \"Ab\": \"Gs\",\n",
    "        \"Cb\": \"B\",\n",
    "        \"Fb\": \"E\",\n",
    "        \"Bs\": \"C\",\n",
    "        \"Es\": \"F\"\n",
    "    }\n",
    "\n",
    "    for flat, sharp in flat_to_sharp.items():\n",
    "        if simplified.startswith(flat):\n",
    "            return sharp + simplified[len(flat):]\n",
    "\n",
    "    return simplified\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea5c944c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7k/s33bvpvd04q3y60x6szp7f2m0000gn/T/ipykernel_1043/3026761472.py:1: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"chordonomicon_v2.csv\", usecols=[\"id\", \"chords\", \"main_genre\"])\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"chordonomicon_v2.csv\", usecols=[\"id\", \"chords\", \"main_genre\"])\n",
    "df[\"chords\"] = (\n",
    "    df[\"chords\"]\n",
    "    .str.split(\" \")\n",
    "    .map(lambda lst: [simplify_and_standardize(x) for x in lst if not x.startswith(\"<\")])\n",
    ")\n",
    "df.to_csv(\"chordonomicon_v2_standardized.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bdec05",
   "metadata": {},
   "source": [
    "## Transpose to all chords\n",
    "Transpose each song to mitigate bias from the key of the song and to augment our data. Also Collapse both sharp and flat accents to sharp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70328e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Transposing songs to all keys ###\n",
    "keys_list = [\"C\", \"Cs\", \"D\", \"Ds\", \"E\", \"F\", \"Fs\", \"G\", \"Gs\", \"A\", \"As\", \"B\"]\n",
    "\n",
    "def transpose_chord(chord: str, variation: int) -> str:\n",
    "    # Identify base note and suffix robustly\n",
    "    if len(chord) >= 2 and chord[1] == \"s\":\n",
    "        base = chord[:2]\n",
    "        suffix = chord[2:]\n",
    "    else:\n",
    "        base = chord[:1]\n",
    "        suffix = chord[1:]\n",
    "    if base in keys_list:\n",
    "        idx = keys_list.index(base)\n",
    "        new_base = keys_list[(idx + variation) % 12]\n",
    "        return new_base + suffix\n",
    "    return chord  # If not found, return as is\n",
    "\n",
    "def augment_keys(df):\n",
    "    augmented_rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        for variation in range(12):\n",
    "            new_row = row.copy()\n",
    "            if variation == 0:\n",
    "                new_row[\"original_key\"] = True\n",
    "            else:\n",
    "                new_row[\"original_key\"] = False\n",
    "            new_row[\"added_semitones\"] = variation\n",
    "            new_row[\"chords\"] = [transpose_chord(chord, variation) for chord in row[\"chords\"]]\n",
    "            augmented_rows.append(new_row)\n",
    "    return pd.DataFrame(augmented_rows)\n",
    "\n",
    "def standardize_chord_prefix(chord: str) -> str:\n",
    "    # Map flat notes to their sharp equivalents\n",
    "    flat_to_sharp = {\n",
    "        \"Bb\": \"As\",\n",
    "        \"Db\": \"Cs\",\n",
    "        \"Eb\": \"Ds\",\n",
    "        \"Gb\": \"Fs\",\n",
    "        \"Ab\": \"Gs\",\n",
    "        \"Cb\": \"B\",\n",
    "        \"Fb\": \"E\",\n",
    "        \"Bs\": \"C\",\n",
    "        \"Es\": \"F\"\n",
    "    }\n",
    "    for flat, sharp in flat_to_sharp.items():\n",
    "        if chord.startswith(flat):\n",
    "            return sharp + chord[len(flat):]\n",
    "    return chord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32de50b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7k/s33bvpvd04q3y60x6szp7f2m0000gn/T/ipykernel_1043/484076371.py:3: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"hf://datasets/ailsntua/Chordonomicon/chordonomicon_v2.csv\",usecols=[\"id\", \"chords\", \"main_genre\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                             chords  original_key  \\\n",
      "0   1  [C, F, C, E, Amin, C, F, C, G, C, F, C, E, Ami...          True   \n",
      "0   1  [Cs, Fs, Cs, F, Asmin, Cs, Fs, Cs, Gs, Cs, Fs,...         False   \n",
      "0   1  [D, G, D, Fs, Bmin, D, G, D, A, D, G, D, Fs, B...         False   \n",
      "0   1  [Ds, Gs, Ds, G, Cmin, Ds, Gs, Ds, As, Ds, Gs, ...         False   \n",
      "0   1  [E, A, E, Gs, Csmin, E, A, E, B, E, A, E, Gs, ...         False   \n",
      "0   1  [F, As, F, A, Dmin, F, As, F, C, F, As, F, A, ...         False   \n",
      "0   1  [Fs, B, Fs, As, Dsmin, Fs, B, Fs, Cs, Fs, B, F...         False   \n",
      "0   1  [G, C, G, B, Emin, G, C, G, D, G, C, G, B, Emi...         False   \n",
      "0   1  [Gs, Cs, Gs, C, Fmin, Gs, Cs, Gs, Ds, Gs, Cs, ...         False   \n",
      "0   1  [A, D, A, Cs, Fsmin, A, D, A, E, A, D, A, Cs, ...         False   \n",
      "0   1  [As, Ds, As, D, Gmin, As, Ds, As, F, As, Ds, A...         False   \n",
      "0   1  [B, E, B, Ds, Gsmin, B, E, B, Fs, B, E, B, Ds,...         False   \n",
      "4   5  [C, G, C, G, C, F, Dmin, G, Dmin, G, C, G, C, ...          True   \n",
      "4   5  [Cs, Gs, Cs, Gs, Cs, Fs, Dsmin, Gs, Dsmin, Gs,...         False   \n",
      "4   5  [D, A, D, A, D, G, Emin, A, Emin, A, D, A, D, ...         False   \n",
      "\n",
      "   added_semitones  \n",
      "0                0  \n",
      "0                1  \n",
      "0                2  \n",
      "0                3  \n",
      "0                4  \n",
      "0                5  \n",
      "0                6  \n",
      "0                7  \n",
      "0                8  \n",
      "0                9  \n",
      "0               10  \n",
      "0               11  \n",
      "4                0  \n",
      "4                1  \n",
      "4                2  \n"
     ]
    }
   ],
   "source": [
    "# Writing transposed dataset to csv\n",
    "def get_pop_chords_df():\n",
    "    df = pd.read_csv(\"hf://datasets/ailsntua/Chordonomicon/chordonomicon_v2.csv\",usecols=[\"id\", \"chords\", \"main_genre\"])\n",
    "    pop_df = df[df[\"main_genre\"] == \"pop\"][[\"id\", \"chords\"]].copy()\n",
    "    pop_df[\"chords\"] = pop_df[\"chords\"].str.split(\" \")\n",
    "    pop_df[\"chords\"] = pop_df[\"chords\"].map(\n",
    "        lambda chords: [simplify_chord(standardize_chord_prefix(chord)) for chord in chords if not chord.startswith(\"<\")]\n",
    "    )\n",
    "\n",
    "    pop_df[\"original_key\"] = True\n",
    "    pop_df[\"added_semitones\"] = 0\n",
    "    return pop_df\n",
    "\n",
    "pop_chords_df = get_pop_chords_df()\n",
    "augmented_df = augment_keys(pop_chords_df)\n",
    "print(augmented_df.head(15))\n",
    "augmented_df.to_csv(\"chordonomicon_v2_augmented.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc79ae1f",
   "metadata": {},
   "source": [
    "# N-gram Learning\n",
    "Compute n-gram counts using CountVectorizer library (usually used for bag of n-grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1f11b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_n_grams(data, n: int = 1) -> pd.DataFrame:\n",
    "    word_vectorizer = CountVectorizer(\n",
    "        ngram_range=(1, n),\n",
    "        analyzer=\"word\",\n",
    "        token_pattern=r\"(?u)\\b\\w+\\b\",\n",
    "        lowercase=False,\n",
    "    )\n",
    "\n",
    "    sparse_matrix = word_vectorizer.fit_transform(\n",
    "        data.map(lambda chords: \" \".join(chords))\n",
    "    )\n",
    "\n",
    "    frequencies = sum(sparse_matrix).toarray()[0]\n",
    "\n",
    "    df_all = pd.DataFrame(\n",
    "        frequencies,\n",
    "        index=word_vectorizer.get_feature_names_out(),\n",
    "        columns=[\"count\"],\n",
    "    )\n",
    "\n",
    "    return df_all.groupby(by=lambda chords: len(chords.split(\" \")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0f1820",
   "metadata": {},
   "source": [
    "Import our processed dataset and compute n-gram counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84a72a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 1-gram counts for simplified ---\n",
      "         count\n",
      "Gbmin    13921\n",
      "Dbmin    25731\n",
      "Bs       43297\n",
      "Abmin    50386\n",
      "Es       53824\n",
      "Asmin    76742\n",
      "Ebmin    98737\n",
      "Gb      115516\n",
      "Dsmin   136273\n",
      "Bbmin   173213\n",
      "Db      226807\n",
      "Fmin    349631\n",
      "As      361219\n",
      "Gsmin   365534\n",
      "Ds      370729\n",
      "Gs      379959\n",
      "Ab      415987\n",
      "Cs      458960\n",
      "Cmin    485114\n",
      "Eb      583180\n",
      "Gmin    656014\n",
      "Csmin   700142\n",
      "Fs      842932\n",
      "Fsmin   991863\n",
      "Bb     1147575\n",
      "Dmin   1449889\n",
      "Bmin   1633942\n",
      "B      1760255\n",
      "Emin   2989466\n",
      "E      3172313\n",
      "Amin   3277296\n",
      "F      3718124\n",
      "A      4527730\n",
      "D      6005289\n",
      "C      6627164\n",
      "G      7709880\n",
      "\n",
      "--- 2-gram counts for simplified ---\n",
      "               count\n",
      "Asmin Gbmin        1\n",
      "Gsmin Gbmin        1\n",
      "Dsmin Gbmin        1\n",
      "Dbmin Dsmin        1\n",
      "Dsmin Dbmin        2\n",
      "...              ...\n",
      "F C          1275024\n",
      "D G          1604703\n",
      "G D          1747895\n",
      "G C          1889671\n",
      "C G          2208974\n",
      "\n",
      "[1293 rows x 1 columns]\n",
      "\n",
      "--- 3-gram counts for simplified ---\n",
      "                   count\n",
      "Dsmin Ebmin Gs         1\n",
      "Fsmin Fmin Dbmin       1\n",
      "Fsmin Fmin Db          1\n",
      "Cs Gmin Asmin          1\n",
      "Ebmin Amin Fsmin       1\n",
      "...                  ...\n",
      "F C G             465948\n",
      "D G D             502138\n",
      "C G D             563878\n",
      "C G C             584210\n",
      "G C G             680778\n",
      "\n",
      "[35574 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import json\n",
    "\n",
    "def load_chords_from_csv(path):\n",
    "    df = pd.read_csv(path, usecols=['chords'])\n",
    "    # If chords are stored as a list string, use ast.literal_eval\n",
    "    try:\n",
    "        chords = df['chords'].apply(ast.literal_eval)\n",
    "    except Exception:\n",
    "        chords = df['chords'].str.split(\" \")\n",
    "    return chords\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, path in [\n",
    "    (\"simplified\", \"chordonomicon_v2_simplified.csv\"),\n",
    "    (\"standardized\", \"chordonomicon_v2_standardized.csv\"),\n",
    "    (\"augmented\", \"chordonomicon_v2_augmented.csv\")\n",
    "]:\n",
    "    chords = load_chords_from_csv(path)\n",
    "    n_gram_counts = count_n_grams(chords, 3)\n",
    "    results[name] = {}\n",
    "    for key, _ in n_gram_counts:\n",
    "        df = n_gram_counts.get_group(key).sort_values(by='count')\n",
    "        results[name][f\"{key}-gram\"] = df.reset_index().to_dict(orient=\"records\")\n",
    "        if name == \"simplified\":\n",
    "            print(f\"\\n--- {key}-gram counts for simplified ---\")\n",
    "            print(df)\n",
    "\n",
    "with open(\"n_gram_counts_results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bbec61",
   "metadata": {},
   "source": [
    "Calculate transition matrix probabilities using counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d73a28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standardized (count): 24\n",
      "['A', 'Amin', 'As', 'Asmin', 'B', 'Bmin', 'C', 'Cmin', 'Cs', 'Csmin', 'D', 'Dmin', 'Ds', 'Dsmin', 'E', 'Emin', 'F', 'Fmin', 'Fs', 'Fsmin', 'G', 'Gmin', 'Gs', 'Gsmin']\n",
      "simplified (count): 34\n",
      "['A', 'Ab', 'Abmin', 'Amin', 'As', 'Asmin', 'B', 'Bb', 'Bbmin', 'Bmin', 'C', 'Cmin', 'Cs', 'Csmin', 'D', 'Db', 'Dbmin', 'Dmin', 'Ds', 'Dsmin', 'E', 'Eb', 'Ebmin', 'Emin', 'F', 'Fmin', 'Fs', 'Fsmin', 'G', 'Gb', 'Gbmin', 'Gmin', 'Gs', 'Gsmin']\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "# base notes and shape of chord names\n",
    "notes = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]\n",
    "# standardized/augmented: no flat spellings (only natural + sharp 's')\n",
    "accs_std = [\"\", \"s\"]\n",
    "# simplified: include flats 'b' in addition to sharps and naturals\n",
    "accs_simpl = [\"\", \"s\", \"b\"]\n",
    "third = [\"\", \"min\"]\n",
    "\n",
    "# exclude weird/duplicate forms for standardized (same as you used)\n",
    "excluded_chords = {\"Bs\", \"Bsmin\", \"Es\", \"Esmin\", \"Cb\", \"Cbmin\", \"Fb\", \"Fbmin\"}\n",
    "\n",
    "# build standardized / augmented list\n",
    "all_chords_std = [note + acc + t for note in notes for acc in accs_std for t in third]\n",
    "all_chords_std = [c for c in all_chords_std if c not in excluded_chords]\n",
    "\n",
    "# build simplified list (includes flats)\n",
    "all_chords_simpl = [note + acc + t for note in notes for acc in accs_simpl for t in third]\n",
    "all_chords_simpl = [c for c in all_chords_simpl if c not in excluded_chords]\n",
    "\n",
    "# final dict\n",
    "all_chords_dict = {\n",
    "    \"standardized\": sorted(all_chords_std),\n",
    "    \"augmented\": sorted(all_chords_std),   # same as standardized\n",
    "    \"simplified\": sorted(all_chords_simpl),\n",
    "}\n",
    "\n",
    "print(\"standardized (count):\", len(all_chords_dict[\"standardized\"]))\n",
    "print(all_chords_dict[\"standardized\"])\n",
    "print(\"simplified (count):\", len(all_chords_dict[\"simplified\"]))\n",
    "print(all_chords_dict[\"simplified\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "612d407c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate transition matrix probabilities\n",
    "# alpha is additive smoothing\n",
    "\n",
    "def compute_unigram_prob(n_gram_counts, alpha=1.0, input_data=\"simplified\"):\n",
    "    unigram = n_gram_counts.get_group(1)\n",
    "    unigram = unigram.reindex(all_chords_dict[input_data], fill_value=0)\n",
    "    vocab_size = len(all_chords_dict[input_data])\n",
    "    total_count = unigram[\"count\"].sum()\n",
    "\n",
    "    probs = (unigram[\"count\"] + alpha) / (total_count + alpha * vocab_size)\n",
    "    df = pd.DataFrame([probs.values], \n",
    "                      index=[\"\"],\n",
    "                      columns=all_chords_dict[input_data])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34e9b86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_unigram_prob_from_df(unigram_df: pd.DataFrame, alpha: float = 1.0, input_data: str = \"simplified\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute unigram probabilities with additive smoothing directly from a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - unigram_df: DataFrame containing columns ['index', 'count', ...] for 1-grams\n",
    "    - alpha: additive smoothing constant\n",
    "    - input_data: key to select chord vocabulary from all_chords_dict\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: 1-row, columns = chords, values = probability\n",
    "    \"\"\"\n",
    "    # Set index to chord names\n",
    "    unigram_df = unigram_df.set_index(\"index\")\n",
    "\n",
    "    # Reindex to include all possible chords, fill missing with 0\n",
    "    vocab = all_chords_dict[input_data]\n",
    "    unigram_df = unigram_df.reindex(vocab, fill_value=0)\n",
    "\n",
    "    # Compute probabilities with additive smoothing\n",
    "    total_count = unigram_df[\"count\"].sum()\n",
    "    probs = (unigram_df[\"count\"] + alpha) / (total_count + alpha * len(vocab))\n",
    "\n",
    "    # Return as a 1-row DataFrame with chords as columns\n",
    "    return pd.DataFrame([probs.values], columns=vocab, index=[\"\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28ef84b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         A        Ab     Abmin      Amin       As     Asmin         B  \\\n",
      "  0.087244  0.008016  0.000971  0.063149  0.00696  0.001479  0.033918   \n",
      "\n",
      "        Bb     Bbmin      Bmin  ...         F      Fmin        Fs     Fsmin  \\\n",
      "  0.022112  0.003338  0.031484  ...  0.071644  0.006737  0.016242  0.019112   \n",
      "\n",
      "        G        Gb     Gbmin      Gmin        Gs     Gsmin  \n",
      "  0.14856  0.002226  0.000268  0.012641  0.007321  0.007043  \n",
      "\n",
      "[1 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extract unigrams from df_all\n",
    "df_all = results[\"simplified\"][\"1-gram\"]\n",
    "df_all = pd.DataFrame(df_all)\n",
    "df_all[\"ngram_length\"] = 1  # since these are unigrams\n",
    "unigram_df = df_all[df_all[\"ngram_length\"] == 1].copy()\n",
    "\n",
    "# Compute probabilities\n",
    "unigram_probs = compute_unigram_prob_from_df(unigram_df, alpha=1.0, input_data=\"simplified\")\n",
    "\n",
    "print(unigram_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54c480cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "def compute_ngram_prob_from_df(ngram_df, n: int = 2, alpha=1.0, input_data=\"simplified\"):\n",
    "    \"\"\"\n",
    "    Compute n-gram probabilities from a reconstructed DataFrame.\n",
    "    ngram_df: DataFrame with columns ['index', 'count', 'ngram_length'] for n-grams\n",
    "    \"\"\"\n",
    "    ngram = ngram_df.copy()\n",
    "\n",
    "    # use the 'index' column as the n-gram string\n",
    "    ngram[\"evidence\"] = ngram[\"index\"].map(lambda s: \" \".join(s.split()[:-1]))\n",
    "    ngram[\"next\"] = ngram[\"index\"].map(lambda s: s.split()[-1])\n",
    "\n",
    "    # generate all possible (n-1)-length sequences\n",
    "    all_evidence_seq = [\" \".join(evidence) for evidence in itertools.product(all_chords_dict[input_data], repeat=(n - 1))]\n",
    "    full_index = pd.MultiIndex.from_product([all_evidence_seq, all_chords_dict[input_data]], names=[\"evidence\", \"next\"])\n",
    "\n",
    "    # reindex to include all possible n-grams\n",
    "    ngram = ngram.set_index([\"evidence\", \"next\"])\n",
    "    ngram = ngram.reindex(full_index, fill_value=0)\n",
    "\n",
    "    # compute probabilities with additive smoothing\n",
    "    evidence_counts = ngram[\"count\"].groupby(level=\"evidence\").transform(\"sum\")\n",
    "    vocab_size = len(all_chords_dict[input_data])\n",
    "    ngram[\"prob\"] = (ngram[\"count\"] + alpha) / (evidence_counts + alpha * vocab_size)\n",
    "\n",
    "    # return as a 2D DataFrame: rows=evidence, columns=next chord\n",
    "    return ngram[\"prob\"].unstack(fill_value=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c19379a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34, 34)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>next</th>\n",
       "      <th>A</th>\n",
       "      <th>Ab</th>\n",
       "      <th>Abmin</th>\n",
       "      <th>Amin</th>\n",
       "      <th>As</th>\n",
       "      <th>Asmin</th>\n",
       "      <th>B</th>\n",
       "      <th>Bb</th>\n",
       "      <th>Bbmin</th>\n",
       "      <th>Bmin</th>\n",
       "      <th>...</th>\n",
       "      <th>F</th>\n",
       "      <th>Fmin</th>\n",
       "      <th>Fs</th>\n",
       "      <th>Fsmin</th>\n",
       "      <th>G</th>\n",
       "      <th>Gb</th>\n",
       "      <th>Gbmin</th>\n",
       "      <th>Gmin</th>\n",
       "      <th>Gs</th>\n",
       "      <th>Gsmin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evidence</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ab</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abmin</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amin</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>As</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asmin</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bb</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bbmin</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bmin</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cmin</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cs</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Csmin</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Db</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dbmin</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dmin</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ds</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dsmin</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eb</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ebmin</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emin</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fmin</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fs</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fsmin</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gb</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gbmin</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gmin</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gs</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gsmin</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34 rows  34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "next             A        Ab     Abmin      Amin        As     Asmin  \\\n",
       "evidence                                                               \n",
       "A         0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Ab        0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Abmin     0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Amin      0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "As        0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Asmin     0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "B         0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Bb        0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Bbmin     0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Bmin      0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "C         0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Cmin      0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Cs        0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Csmin     0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "D         0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Db        0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Dbmin     0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Dmin      0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Ds        0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Dsmin     0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "E         0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Eb        0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Ebmin     0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Emin      0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "F         0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Fmin      0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Fs        0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Fsmin     0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "G         0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Gb        0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Gbmin     0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Gmin      0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Gs        0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Gsmin     0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "\n",
       "next             B        Bb     Bbmin      Bmin  ...         F      Fmin  \\\n",
       "evidence                                          ...                       \n",
       "A         0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "Ab        0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "Abmin     0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "Amin      0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "As        0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "Asmin     0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "B         0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "Bb        0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "Bbmin     0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "Bmin      0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "C         0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "Cmin      0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "Cs        0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "Csmin     0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "D         0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "Db        0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "Dbmin     0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "Dmin      0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "Ds        0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "Dsmin     0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "E         0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "Eb        0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "Ebmin     0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "Emin      0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "F         0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "Fmin      0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "Fs        0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "Fsmin     0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "G         0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "Gb        0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "Gbmin     0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "Gmin      0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "Gs        0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "Gsmin     0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "\n",
       "next            Fs     Fsmin         G        Gb     Gbmin      Gmin  \\\n",
       "evidence                                                               \n",
       "A         0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Ab        0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Abmin     0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Amin      0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "As        0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Asmin     0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "B         0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Bb        0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Bbmin     0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Bmin      0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "C         0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Cmin      0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Cs        0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Csmin     0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "D         0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Db        0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Dbmin     0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Dmin      0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Ds        0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Dsmin     0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "E         0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Eb        0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Ebmin     0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Emin      0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "F         0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Fmin      0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Fs        0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Fsmin     0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "G         0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Gb        0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Gbmin     0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Gmin      0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Gs        0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Gsmin     0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "\n",
       "next            Gs     Gsmin  \n",
       "evidence                      \n",
       "A         0.029412  0.029412  \n",
       "Ab        0.029412  0.029412  \n",
       "Abmin     0.029412  0.029412  \n",
       "Amin      0.029412  0.029412  \n",
       "As        0.029412  0.029412  \n",
       "Asmin     0.029412  0.029412  \n",
       "B         0.029412  0.029412  \n",
       "Bb        0.029412  0.029412  \n",
       "Bbmin     0.029412  0.029412  \n",
       "Bmin      0.029412  0.029412  \n",
       "C         0.029412  0.029412  \n",
       "Cmin      0.029412  0.029412  \n",
       "Cs        0.029412  0.029412  \n",
       "Csmin     0.029412  0.029412  \n",
       "D         0.029412  0.029412  \n",
       "Db        0.029412  0.029412  \n",
       "Dbmin     0.029412  0.029412  \n",
       "Dmin      0.029412  0.029412  \n",
       "Ds        0.029412  0.029412  \n",
       "Dsmin     0.029412  0.029412  \n",
       "E         0.029412  0.029412  \n",
       "Eb        0.029412  0.029412  \n",
       "Ebmin     0.029412  0.029412  \n",
       "Emin      0.029412  0.029412  \n",
       "F         0.029412  0.029412  \n",
       "Fmin      0.029412  0.029412  \n",
       "Fs        0.029412  0.029412  \n",
       "Fsmin     0.029412  0.029412  \n",
       "G         0.029412  0.029412  \n",
       "Gb        0.029412  0.029412  \n",
       "Gbmin     0.029412  0.029412  \n",
       "Gmin      0.029412  0.029412  \n",
       "Gs        0.029412  0.029412  \n",
       "Gsmin     0.029412  0.029412  \n",
       "\n",
       "[34 rows x 34 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_df = df_all[df_all[\"ngram_length\"] == 2].copy()\n",
    "bigram_probs = compute_ngram_prob_from_df(bigram_df, n=2, alpha=1.0, input_data=\"simplified\")\n",
    "print(bigram_probs.shape)\n",
    "bigram_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b81451f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1156, 34)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>next</th>\n",
       "      <th>A</th>\n",
       "      <th>Ab</th>\n",
       "      <th>Abmin</th>\n",
       "      <th>Amin</th>\n",
       "      <th>As</th>\n",
       "      <th>Asmin</th>\n",
       "      <th>B</th>\n",
       "      <th>Bb</th>\n",
       "      <th>Bbmin</th>\n",
       "      <th>Bmin</th>\n",
       "      <th>...</th>\n",
       "      <th>F</th>\n",
       "      <th>Fmin</th>\n",
       "      <th>Fs</th>\n",
       "      <th>Fsmin</th>\n",
       "      <th>G</th>\n",
       "      <th>Gb</th>\n",
       "      <th>Gbmin</th>\n",
       "      <th>Gmin</th>\n",
       "      <th>Gs</th>\n",
       "      <th>Gsmin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evidence</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A A</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A Ab</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A Abmin</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A Amin</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A As</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gsmin Gb</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gsmin Gbmin</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gsmin Gmin</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gsmin Gs</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gsmin Gsmin</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1156 rows  34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "next                A        Ab     Abmin      Amin        As     Asmin  \\\n",
       "evidence                                                                  \n",
       "A A          0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "A Ab         0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "A Abmin      0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "A Amin       0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "A As         0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "...               ...       ...       ...       ...       ...       ...   \n",
       "Gsmin Gb     0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Gsmin Gbmin  0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Gsmin Gmin   0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Gsmin Gs     0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Gsmin Gsmin  0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "\n",
       "next                B        Bb     Bbmin      Bmin  ...         F      Fmin  \\\n",
       "evidence                                             ...                       \n",
       "A A          0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "A Ab         0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "A Abmin      0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "A Amin       0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "A As         0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "...               ...       ...       ...       ...  ...       ...       ...   \n",
       "Gsmin Gb     0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "Gsmin Gbmin  0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "Gsmin Gmin   0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "Gsmin Gs     0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "Gsmin Gsmin  0.029412  0.029412  0.029412  0.029412  ...  0.029412  0.029412   \n",
       "\n",
       "next               Fs     Fsmin         G        Gb     Gbmin      Gmin  \\\n",
       "evidence                                                                  \n",
       "A A          0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "A Ab         0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "A Abmin      0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "A Amin       0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "A As         0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "...               ...       ...       ...       ...       ...       ...   \n",
       "Gsmin Gb     0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Gsmin Gbmin  0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Gsmin Gmin   0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Gsmin Gs     0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "Gsmin Gsmin  0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
       "\n",
       "next               Gs     Gsmin  \n",
       "evidence                         \n",
       "A A          0.029412  0.029412  \n",
       "A Ab         0.029412  0.029412  \n",
       "A Abmin      0.029412  0.029412  \n",
       "A Amin       0.029412  0.029412  \n",
       "A As         0.029412  0.029412  \n",
       "...               ...       ...  \n",
       "Gsmin Gb     0.029412  0.029412  \n",
       "Gsmin Gbmin  0.029412  0.029412  \n",
       "Gsmin Gmin   0.029412  0.029412  \n",
       "Gsmin Gs     0.029412  0.029412  \n",
       "Gsmin Gsmin  0.029412  0.029412  \n",
       "\n",
       "[1156 rows x 34 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_df = df_all[df_all[\"ngram_length\"] == 3].copy()\n",
    "trigram_probs = compute_ngram_prob_from_df(trigram_df, n=3, alpha=1.0, input_data=\"simplified\")\n",
    "print(trigram_probs.shape)\n",
    "trigram_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa46131",
   "metadata": {},
   "source": [
    "# Inference\n",
    "Deterministic and probabilistic methods, we are generating a 16 chord song simply from the log-probabilities from our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84ab1ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deterministic_inference(evidence):\n",
    "    # evidence: string of n-1 space-separated chords\n",
    "    \n",
    "    n = len(evidence.split()) + 1\n",
    "    ngram_probs = unigram_probs if n == 1 else (bigram_probs if n == 2 else trigram_probs)\n",
    "\n",
    "    if evidence not in ngram_probs.index:\n",
    "        raise KeyError(f\"Evidence '{evidence}' not found in {n}-gram table\")\n",
    "    \n",
    "    row_probs = ngram_probs.loc[evidence]\n",
    "    return row_probs.idxmax() # returns next chord w highest prob, if there are several, the first one in col order\n",
    "\n",
    "def probabilistic_inference(evidence):\n",
    "    # evidence: string of n-1 space-separated chords\n",
    "    \n",
    "    n = len(evidence.split()) + 1\n",
    "    ngram_probs = unigram_probs if n == 1 else (bigram_probs if n == 2 else trigram_probs)\n",
    "\n",
    "    if evidence not in ngram_probs.index:\n",
    "        raise KeyError(f\"Evidence '{evidence}' not found in {n}-gram table\")\n",
    "    \n",
    "    row_probs = ngram_probs.loc[evidence]\n",
    "    cdf = np.cumsum(row_probs.values) # create cumulative distribution over next possible chord\n",
    "\n",
    "    # sample over dist\n",
    "    seed = np.random.random()\n",
    "    idx = np.searchsorted(cdf, seed)\n",
    "    \n",
    "    return row_probs.index[idx] # return probabilistically chosen next chord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "798bcfbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['G', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n"
     ]
    }
   ],
   "source": [
    "### test inference for bigram ###\n",
    "seq = []\n",
    "\n",
    "for _ in range(16):\n",
    "    if len(seq) == 0:\n",
    "        evidence = \"\"\n",
    "    elif len(seq) == 1:\n",
    "        evidence = seq[-1]\n",
    "    else:\n",
    "        evidence = \" \".join(seq[-2:])\n",
    "\n",
    "    next_chord = deterministic_inference(evidence) # can change to deterministic_inference()\n",
    "    seq.append(next_chord)\n",
    "\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3734191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['G', 'Db', 'As', 'Dbmin', 'A', 'Bb', 'B', 'Dbmin', 'Ab', 'Fs', 'Bbmin', 'Gmin', 'Bb', 'Dmin', 'F', 'Emin']\n"
     ]
    }
   ],
   "source": [
    "### test inference for bigram ###\n",
    "seq = []\n",
    "\n",
    "for _ in range(16):\n",
    "    if len(seq) == 0:\n",
    "        evidence = \"\"\n",
    "    elif len(seq) == 1:\n",
    "        evidence = seq[-1]\n",
    "    else:\n",
    "        evidence = \" \".join(seq[-2:])\n",
    "\n",
    "    next_chord = probabilistic_inference(evidence) # can change to deterministic_inference()\n",
    "    seq.append(next_chord)\n",
    "\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea16a395",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Evaluate log-likelihood of an n-gram given a song (in this case the first song of the dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aaae9ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def song_log_likelihood_ngram(song, n, ngram_probs):\n",
    "    \"\"\"\n",
    "    song: list of chords for one song\n",
    "    n:    order of n-gram (1, 2, 3, ...)\n",
    "    ngram_probs:\n",
    "        - n=1: pandas Series or 1-row DataFrame with index = chord, value = P(chord)\n",
    "        - n>=2: pandas DataFrame with index = context string, columns = chord, cell = P(target | context)\n",
    "    \"\"\"\n",
    "    ll = 0.0\n",
    "    if len(song) < n:\n",
    "        return 0.0\n",
    "\n",
    "    for t in range(n - 1, len(song)):\n",
    "        if n == 1:\n",
    "            # Unigram: no context, just P(chord)\n",
    "            target = song[t]\n",
    "            # If unigram_probs is a Series:\n",
    "            try:\n",
    "                # Series: P(chord)\n",
    "                p = float(ngram_probs[target])\n",
    "            except KeyError:\n",
    "                # If it's a 1-row DataFrame instead:\n",
    "                try:\n",
    "                    p = float(ngram_probs.loc[:, target].iloc[0])\n",
    "                except Exception:\n",
    "                    p = 1e-12\n",
    "        else:\n",
    "            # Bigram / trigram / ...\n",
    "            context = \" \".join(song[t - (n - 1):t])\n",
    "            target = song[t]\n",
    "\n",
    "            # Only access .loc if both labels exist\n",
    "            if (context in ngram_probs.index) and (target in ngram_probs.columns):\n",
    "                p = float(ngram_probs.loc[context, target])\n",
    "            else:\n",
    "                p = 1e-12\n",
    "\n",
    "        if p <= 0:\n",
    "            p = 1e-12\n",
    "\n",
    "        ll += np.log(p)\n",
    "\n",
    "    return ll\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c27a6598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-155.76098994173117\n",
      "-232.73979462466684\n",
      "-229.21343410005068\n"
     ]
    }
   ],
   "source": [
    "# test log-likelihood\n",
    "song_simplified = ['C', 'F', 'C', 'E', 'Amin', 'C', 'F', 'C', 'G', 'C', 'F', 'C', 'E', 'Amin', 'C', 'F', 'G', 'C', 'F', 'C', 'E', 'Amin', 'C', 'F', 'C', 'G', 'C', 'F', 'C', 'E', 'Amin', 'C', 'F', 'G', 'C', 'F', 'C', 'F', 'C', 'G', 'C', 'F', 'C', 'E', 'Amin', 'C', 'F', 'G', 'C', 'D', 'G', 'D', 'G', 'D', 'A', 'D', 'G', 'D', 'Fs', 'Bmin', 'D', 'G', 'A', 'D', 'G', 'A', 'D']\n",
    "\n",
    "print(song_log_likelihood_ngram(song_simplified, 1, unigram_probs))\n",
    "print(song_log_likelihood_ngram(song_simplified, 2, bigram_probs))\n",
    "print(song_log_likelihood_ngram(song_simplified, 3, trigram_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "937ff550",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsimplified = pd.read_csv(\"chordonomicon_v2_simplified.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5fa56c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "dfsimplified[\"chords\"] = dfsimplified[\"chords\"].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae37215",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7k/s33bvpvd04q3y60x6szp7f2m0000gn/T/ipykernel_1043/3478931182.py:22: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  p = float(ngram_probs[target])\n"
     ]
    }
   ],
   "source": [
    "total_loglik_uni = 0.0\n",
    "total_loglik_bi  = 0.0\n",
    "total_loglik_tri = 0.0\n",
    "song1 = dfsimplified[\"chords\"].iloc[0]\n",
    "for i in range(len(dfsimplified)):\n",
    "    song = dfsimplified[\"chords\"].iloc[i]\n",
    "    ll_uni = song_log_likelihood_ngram(song, 1, unigram_probs)\n",
    "    ll_bi  = song_log_likelihood_ngram(song, 2, bigram_probs)\n",
    "    ll_tri = song_log_likelihood_ngram(song, 3, trigram_probs)\n",
    "    total_loglik_uni += ll_uni\n",
    "    total_loglik_bi  += ll_bi\n",
    "    total_loglik_tri += ll_tri\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8db68090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unigram log-likelihood:  -149349540.74597985\n",
      "Total bigram log-likelihood:   -185539817.00730315\n",
      "Total trigram log-likelihood:  -184812626.0754259\n"
     ]
    }
   ],
   "source": [
    "print(\"Total unigram log-likelihood: \", total_loglik_uni)\n",
    "print(\"Total bigram log-likelihood:  \", total_loglik_bi)\n",
    "print(\"Total trigram log-likelihood: \", total_loglik_tri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ab9f6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average unigram log-likelihood per song:  -219.69403190314287\n",
      "Average bigram log-likelihood per song:   -272.930136064064\n",
      "Average trigram log-likelihood per song:  -271.8604340282255\n"
     ]
    }
   ],
   "source": [
    "avg_uni = total_loglik_uni / len(dfsimplified)\n",
    "avg_bi  = total_loglik_bi  / len(dfsimplified)\n",
    "avg_tri = total_loglik_tri / len(dfsimplified)\n",
    "print(\"Average unigram log-likelihood per song: \", avg_uni)\n",
    "print(\"Average bigram log-likelihood per song:  \", avg_bi)\n",
    "print(\"Average trigram log-likelihood per song: \", avg_tri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7fdd2f",
   "metadata": {},
   "source": [
    "Also compute the top-k accuracy with k = 1,3,5 for the given song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "35d7c6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_accuracy_ngram(song, n, ngram_probs, k=5):\n",
    "    # song: list of chords in song\n",
    "    # n: order of the n-gram model\n",
    "    # ngram_probs: DataFrame with index=evidence, columns=next chords\n",
    "    # k: number of top predictions to consider\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    if len(song) < n:\n",
    "        return 0.0\n",
    "    \n",
    "    for t in range(n-1, len(song)):\n",
    "        if n == 1:\n",
    "            context = \"\"\n",
    "        else:\n",
    "            context = \" \".join(song[t-(n-1):t])\n",
    "        \n",
    "        target = song[t]\n",
    "        \n",
    "        try:\n",
    "            prob_row = ngram_probs.loc[context]\n",
    "            \n",
    "            top_k_chords = prob_row.nlargest(k).index.tolist()\n",
    "            \n",
    "            if target in top_k_chords:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "            \n",
    "        except KeyError:\n",
    "            total += 1\n",
    "    \n",
    "    return correct / total if total > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e02b8e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1: 0.0000\n",
      "Top-3: 0.1333\n",
      "Top-5: 0.1333\n"
     ]
    }
   ],
   "source": [
    "# Test on top-k accuracy\n",
    "print(f\"Top-1: {top_k_accuracy_ngram(seq, 2, bigram_probs, k=1):.4f}\")\n",
    "print(f\"Top-3: {top_k_accuracy_ngram(seq, 2, bigram_probs, k=3):.4f}\")\n",
    "print(f\"Top-5: {top_k_accuracy_ngram(seq, 2, bigram_probs, k=5):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dbef2778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1: 0.0000\n",
      "Top-3: 0.1429\n",
      "Top-5: 0.1429\n"
     ]
    }
   ],
   "source": [
    "# Test on top-k accuracy\n",
    "print(f\"Top-1: {top_k_accuracy_ngram(seq, 3, trigram_probs, k=1):.4f}\")\n",
    "print(f\"Top-3: {top_k_accuracy_ngram(seq, 3, trigram_probs, k=3):.4f}\")\n",
    "print(f\"Top-5: {top_k_accuracy_ngram(seq, 3, trigram_probs, k=5):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c54818",
   "metadata": {},
   "source": [
    "## Inference and evaluation with standardized data\n",
    "Repeat the inference and evaluation using data with only sharp (no flat-sharp duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58fa33a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         A     Amin        As     Asmin        B      Bmin        C      Cmin  \\\n",
      "  0.092315  0.06682  0.007365  0.001565  0.03589  0.033314  0.13512  0.009891   \n",
      "\n",
      "        Cs     Csmin  ...        E      Emin         F      Fmin        Fs  \\\n",
      "  0.009358  0.014275  ...  0.06468  0.060952  0.075808  0.007129  0.017186   \n",
      "\n",
      "     Fsmin         G      Gmin        Gs     Gsmin  \n",
      "  0.020223  0.157195  0.013375  0.007747  0.007453  \n",
      "\n",
      "[1 rows x 24 columns]\n",
      "(24, 24)\n",
      "(576, 24)\n"
     ]
    }
   ],
   "source": [
    "# Extract unigrams from df_all\n",
    "unigram_df = df_all[df_all[\"ngram_length\"] == 1].copy()\n",
    "\n",
    "# Compute probabilities\n",
    "unigram_probs = compute_unigram_prob_from_df(unigram_df, alpha=1.0, input_data=\"standardized\")\n",
    "\n",
    "print(unigram_probs)\n",
    "\n",
    "bigram_df = df_all[df_all[\"ngram_length\"] == 2].copy()\n",
    "bigram_probs = compute_ngram_prob_from_df(bigram_df, n=2, alpha=1.0, input_data=\"standardized\")\n",
    "print(bigram_probs.shape)\n",
    "\n",
    "trigram_df = df_all[df_all[\"ngram_length\"] == 3].copy()\n",
    "trigram_probs = compute_ngram_prob_from_df(trigram_df, n=3, alpha=1.0, input_data=\"standardized\")\n",
    "print(trigram_probs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2ac9e7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F', 'Emin', 'Fsmin', 'Fsmin', 'C', 'As', 'Dsmin', 'Fs', 'Gmin', 'Ds', 'Amin', 'Gsmin', 'Cs', 'Gmin', 'Cs', 'Gmin']\n"
     ]
    }
   ],
   "source": [
    "### test inference for bigram ###\n",
    "seq = []\n",
    "\n",
    "for _ in range(16):\n",
    "    if len(seq) == 0:\n",
    "        evidence = \"\"\n",
    "    elif len(seq) == 1:\n",
    "        evidence = seq[-1]\n",
    "    else:\n",
    "        evidence = \" \".join(seq[-2:])\n",
    "\n",
    "    next_chord = probabilistic_inference(evidence) # can change to deterministic_inference()\n",
    "    seq.append(next_chord)\n",
    "\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "260c14bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-151.97528736047866\n",
      "-209.75155280296457\n",
      "-206.57349897261662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7k/s33bvpvd04q3y60x6szp7f2m0000gn/T/ipykernel_1043/3478931182.py:22: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  p = float(ngram_probs[target])\n"
     ]
    }
   ],
   "source": [
    "# test log-likelihood\n",
    "song_standardized = ['C', 'F', 'C', 'E', 'Amin', 'C', 'F', 'C', 'G', 'C', 'F', 'C', 'E', 'Amin', 'C', 'F', 'G', 'C', 'F', 'C', 'E', 'Amin', 'C', 'F', 'C', 'G', 'C', 'F', 'C', 'E', 'Amin', 'C', 'F', 'G', 'C', 'F', 'C', 'F', 'C', 'G', 'C', 'F', 'C', 'E', 'Amin', 'C', 'F', 'G', 'C', 'D', 'G', 'D', 'G', 'D', 'A', 'D', 'G', 'D', 'Fs', 'Bmin', 'D', 'G', 'A', 'D', 'G', 'A', 'D']\n",
    "print(song_log_likelihood_ngram(song_standardized, 1, unigram_probs))\n",
    "print(song_log_likelihood_ngram(song_standardized, 2, bigram_probs))\n",
    "print(song_log_likelihood_ngram(song_standardized, 3, trigram_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b6cab787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7k/s33bvpvd04q3y60x6szp7f2m0000gn/T/ipykernel_1043/3478931182.py:22: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  p = float(ngram_probs[target])\n"
     ]
    }
   ],
   "source": [
    "total_loglik_uni = 0.0\n",
    "total_loglik_bi  = 0.0\n",
    "total_loglik_tri = 0.0\n",
    "dfstandardized = pd.read_csv(\"chordonomicon_v2_standardized.csv\")\n",
    "import ast\n",
    "dfstandardized[\"chords\"] = dfstandardized[\"chords\"].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
    ")   \n",
    "for i in range(len(dfstandardized)):\n",
    "    song = dfstandardized[\"chords\"].iloc[i]\n",
    "    ll_uni = song_log_likelihood_ngram(song, 1, unigram_probs)\n",
    "    ll_bi  = song_log_likelihood_ngram(song, 2, bigram_probs)\n",
    "    ll_tri = song_log_likelihood_ngram(song, 3, trigram_probs)\n",
    "    total_loglik_uni += ll_uni\n",
    "    total_loglik_bi  += ll_bi\n",
    "    total_loglik_tri += ll_tri\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d9efff39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unigram log-likelihood:  -145063013.37622666\n",
      "Total bigram log-likelihood:   -163081282.50112063\n",
      "Total trigram log-likelihood:  -160921219.69565123\n",
      "Average unigram log-likelihood per song:  -213.38852553184458\n",
      "Average bigram log-likelihood per song:   -239.8935028634901\n",
      "Average trigram log-likelihood per song:  -236.71603807499957\n"
     ]
    }
   ],
   "source": [
    "print(\"Total unigram log-likelihood: \", total_loglik_uni)\n",
    "print(\"Total bigram log-likelihood:  \", total_loglik_bi)\n",
    "print(\"Total trigram log-likelihood: \", total_loglik_tri)\n",
    "avg_uni = total_loglik_uni / len(dfstandardized)\n",
    "avg_bi  = total_loglik_bi  / len(dfstandardized)\n",
    "avg_tri = total_loglik_tri / len(dfstandardized)\n",
    "print(\"Average unigram log-likelihood per song: \", avg_uni)\n",
    "print(\"Average bigram log-likelihood per song:  \", avg_bi)\n",
    "print(\"Average trigram log-likelihood per song: \", avg_tri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ef3327d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1: 0.0000\n",
      "Top-3: 0.0000\n",
      "Top-5: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Test on top-k accuracy\n",
    "print(f\"Top-1: {top_k_accuracy_ngram(seq, 2, bigram_probs, k=1):.4f}\")\n",
    "print(f\"Top-3: {top_k_accuracy_ngram(seq, 2, bigram_probs, k=3):.4f}\")\n",
    "print(f\"Top-5: {top_k_accuracy_ngram(seq, 2, bigram_probs, k=5):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5364e36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1: 0.0000\n",
      "Top-3: 0.0000\n",
      "Top-5: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Test on top-k accuracy\n",
    "print(f\"Top-1: {top_k_accuracy_ngram(seq, 3, trigram_probs, k=1):.4f}\")\n",
    "print(f\"Top-3: {top_k_accuracy_ngram(seq, 3, trigram_probs, k=3):.4f}\")\n",
    "print(f\"Top-5: {top_k_accuracy_ngram(seq, 3, trigram_probs, k=5):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed3da76",
   "metadata": {},
   "source": [
    "## Inference and evaluation with augmented data\n",
    "Repeat the inference and evaluation with the augmented data through transpositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "81ecf456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         A     Amin        As     Asmin        B      Bmin        C      Cmin  \\\n",
      "  0.092315  0.06682  0.007365  0.001565  0.03589  0.033314  0.13512  0.009891   \n",
      "\n",
      "        Cs     Csmin  ...        E      Emin         F      Fmin        Fs  \\\n",
      "  0.009358  0.014275  ...  0.06468  0.060952  0.075808  0.007129  0.017186   \n",
      "\n",
      "     Fsmin         G      Gmin        Gs     Gsmin  \n",
      "  0.020223  0.157195  0.013375  0.007747  0.007453  \n",
      "\n",
      "[1 rows x 24 columns]\n",
      "(24, 24)\n",
      "(576, 24)\n"
     ]
    }
   ],
   "source": [
    "# Extract unigrams from df_all\n",
    "unigram_df = df_all[df_all[\"ngram_length\"] == 1].copy()\n",
    "\n",
    "# Compute probabilities\n",
    "unigram_probs = compute_unigram_prob_from_df(unigram_df, alpha=1.0, input_data=\"augmented\")\n",
    "\n",
    "print(unigram_probs)\n",
    "\n",
    "bigram_df = df_all[df_all[\"ngram_length\"] == 2].copy()\n",
    "bigram_probs = compute_ngram_prob_from_df(bigram_df, n=2, alpha=1.0, input_data=\"augmented\")\n",
    "print(bigram_probs.shape)\n",
    "\n",
    "trigram_df = df_all[df_all[\"ngram_length\"] == 3].copy()\n",
    "trigram_probs = compute_ngram_prob_from_df(trigram_df, n=3, alpha=1.0, input_data=\"augmented\")\n",
    "print(trigram_probs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "43192e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B', 'Amin', 'Cs', 'D', 'Cmin', 'D', 'Dmin', 'Gsmin', 'C', 'D', 'Cs', 'Cmin', 'Bmin', 'Gmin', 'Asmin', 'Gmin']\n"
     ]
    }
   ],
   "source": [
    "### test inference for bigram ###\n",
    "seq = []\n",
    "\n",
    "for _ in range(16):\n",
    "    if len(seq) == 0:\n",
    "        evidence = \"\"\n",
    "    elif len(seq) == 1:\n",
    "        evidence = seq[-1]\n",
    "    else:\n",
    "        evidence = \" \".join(seq[-2:])\n",
    "\n",
    "    next_chord = probabilistic_inference(evidence) # can change to deterministic_inference()\n",
    "    seq.append(next_chord)\n",
    "\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2a7dc2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-151.97528736047866\n",
      "-209.75155280296457\n",
      "-206.57349897261662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7k/s33bvpvd04q3y60x6szp7f2m0000gn/T/ipykernel_1043/3478931182.py:22: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  p = float(ngram_probs[target])\n"
     ]
    }
   ],
   "source": [
    "# test log-likelihood\n",
    "song_augmented = ['C', 'F', 'C', 'E', 'Amin', 'C', 'F', 'C', 'G', 'C', 'F', 'C', 'E', 'Amin', 'C', 'F', 'G', 'C', 'F', 'C', 'E', 'Amin', 'C', 'F', 'C', 'G', 'C', 'F', 'C', 'E', 'Amin', 'C', 'F', 'G', 'C', 'F', 'C', 'F', 'C', 'G', 'C', 'F', 'C', 'E', 'Amin', 'C', 'F', 'G', 'C', 'D', 'G', 'D', 'G', 'D', 'A', 'D', 'G', 'D', 'Fs', 'Bmin', 'D', 'G', 'A', 'D', 'G', 'A', 'D']\n",
    "print(song_log_likelihood_ngram(song_augmented, 1, unigram_probs))\n",
    "print(song_log_likelihood_ngram(song_augmented, 2, bigram_probs))\n",
    "print(song_log_likelihood_ngram(song_augmented, 3, trigram_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "43e6cd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7k/s33bvpvd04q3y60x6szp7f2m0000gn/T/ipykernel_1043/3478931182.py:22: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  p = float(ngram_probs[target])\n"
     ]
    }
   ],
   "source": [
    "total_loglik_uni = 0.0\n",
    "total_loglik_bi  = 0.0\n",
    "total_loglik_tri = 0.0\n",
    "dfaugmented = pd.read_csv(\"chordonomicon_v2_augmented.csv\")\n",
    "import ast\n",
    "dfaugmented[\"chords\"] = dfaugmented[\"chords\"].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "for i in range(len(dfaugmented)):\n",
    "    song = dfaugmented[\"chords\"].iloc[i]\n",
    "    ll_uni = song_log_likelihood_ngram(song, 1, unigram_probs)\n",
    "    ll_bi  = song_log_likelihood_ngram(song, 2, bigram_probs)\n",
    "    ll_tri = song_log_likelihood_ngram(song, 3, trigram_probs)\n",
    "    total_loglik_uni += ll_uni\n",
    "    total_loglik_bi  += ll_bi\n",
    "    total_loglik_tri += ll_tri\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "387ba894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unigram log-likelihood:  -295845678.4015553\n",
      "Total bigram log-likelihood:   -254828038.64340723\n",
      "Total trigram log-likelihood:  -251579749.82337487\n",
      "Average unigram log-likelihood per song:  -289.41487977299926\n",
      "Average bigram log-likelihood per song:   -249.28884060516054\n",
      "Average trigram log-likelihood per song:  -246.1111598514751\n"
     ]
    }
   ],
   "source": [
    "print(\"Total unigram log-likelihood: \", total_loglik_uni)\n",
    "print(\"Total bigram log-likelihood:  \", total_loglik_bi)\n",
    "print(\"Total trigram log-likelihood: \", total_loglik_tri)\n",
    "avg_uni = total_loglik_uni / len(dfaugmented)\n",
    "avg_bi  = total_loglik_bi  / len(dfaugmented)  \n",
    "avg_tri = total_loglik_tri / len(dfaugmented)\n",
    "print(\"Average unigram log-likelihood per song: \", avg_uni)\n",
    "print(\"Average bigram log-likelihood per song:  \", avg_bi)\n",
    "print(\"Average trigram log-likelihood per song: \", avg_tri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fd7f7118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1: 0.0000\n",
      "Top-3: 0.0667\n",
      "Top-5: 0.1333\n"
     ]
    }
   ],
   "source": [
    "# Test on top-k accuracy\n",
    "print(f\"Top-1: {top_k_accuracy_ngram(seq, 2, bigram_probs, k=1):.4f}\")\n",
    "print(f\"Top-3: {top_k_accuracy_ngram(seq, 2, bigram_probs, k=3):.4f}\")\n",
    "print(f\"Top-5: {top_k_accuracy_ngram(seq, 2, bigram_probs, k=5):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f929b942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1: 0.0000\n",
      "Top-3: 0.0000\n",
      "Top-5: 0.0714\n"
     ]
    }
   ],
   "source": [
    "# Test on top-k accuracy\n",
    "print(f\"Top-1: {top_k_accuracy_ngram(seq, 3, trigram_probs, k=1):.4f}\")\n",
    "print(f\"Top-3: {top_k_accuracy_ngram(seq, 3, trigram_probs, k=3):.4f}\")\n",
    "print(f\"Top-5: {top_k_accuracy_ngram(seq, 3, trigram_probs, k=5):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
